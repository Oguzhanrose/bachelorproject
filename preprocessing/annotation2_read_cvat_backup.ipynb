{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File description\n",
    "We annotated the videos using the open source annotation tool `cvat`. We had some problems regarding the export of all the annotations. The main problem was that we needed all annotation to be specifically labeled according to date, time and location of recording. This was not possible and we therefor had to find a creative solution. In `cvat` it's possible to take a backup of your projects and all the individual tasks contained within this project. This backup contain all the information we needed, but it was a pain to extract it, and included a lot of trial an error. But the main approach can be simplified into these steps:\n",
    "\n",
    "    1.) Extract the video and its corresponding bounding boxes from the backup file\n",
    "    2.) Match the location+date+video with a dataframe `df_video_info` containing precise time information on the videos\n",
    "    3.) Extract the the precise time (hours+minuts) from `df_video_info` match\n",
    "    4.) Break the videos into individual frames with their corresponding bounding box annotation \n",
    "    5.) Transform BBs into YOLO-format and save both images and BBs to disk\n",
    "    6.) Make a dataframe with all available information \n",
    "<br>\n",
    "<br>\n",
    "The resulting dataframe looks something like this (Some columns and rows are missing)\n",
    "<img src=\"../illustration_images/df_info_example.png\" width=\"800\" /> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dutils as U\n",
    "U.jupyter_ipython.adjust_screen_width(75)\n",
    "from dutils.jupyter_ipython import show_image as show\n",
    "import seaborn; seaborn.set_style(\"whitegrid\")\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import random\n",
    "import zipfile\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup - paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack zip file\n",
    "backup_zip_path = \"../cvat/project_bachelor_combined_backup_2022_04_13_21_38_08.zip\"\n",
    "backup_folder_path = backup_zip_path[:-4]\n",
    "assert os.path.isfile(backup_zip_path) and (backup_zip_path[-4:] == \".zip\"), \"Backup file is invalid\"\n",
    "assert not os.path.exists(backup_folder_path), \"Attempt to unpack into a folder that already exists\"\n",
    "with zipfile.ZipFile(backup_zip_path) as zip_file:\n",
    "        zip_file.extractall(backup_folder_path)\n",
    "assert os.path.isdir(backup_folder_path)\n",
    "\n",
    "# Make dataset folders\n",
    "save_path_csv = \"../dataset/data_final\"\n",
    "os.mkdir(save_path_csv)\n",
    "save_path = \"../dataset/data_final/data\"\n",
    "os.mkdir(save_path)\n",
    "\n",
    "# Extract project labels\n",
    "project_settings_path = glob(os.path.join(backup_folder_path, \"*.json\"))\n",
    "assert len(project_settings_path) == 1\n",
    "\n",
    "df_project_settings = pd.read_json(project_settings_path[0])\n",
    "project_labels = df_project_settings[\"labels\"].apply(lambda x: x[\"name\"]).to_list()\n",
    "project_labels_map = {label:i for i, label in enumerate(project_labels)}\n",
    "assert len(project_labels) == 15\n",
    "\n",
    "# Tasks paths\n",
    "task_folder_paths = [task_path for task_path in glob(os.path.join(backup_folder_path, \"*\")) if task_path[-5:] != \".json\"]\n",
    "task_folder_paths = sorted(task_folder_paths, key=lambda x: int(x.split(os.sep)[-1].split(\"_\")[-1])) # Number sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup - dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video info (this is used to add time info)\n",
    "df_video_info = pd.read_csv(\"../video_data/video_info.csv\")\n",
    "df_video_info[\"mapping_key\"] = df_video_info[\"mapping_key\"].apply(lambda x: x.replace(\"/\", \"_\"))\n",
    "df_video_info[\"mapping_key\"] = df_video_info[\"mapping_key\"].apply(lambda x: x.replace(\".MP4\", \"\"))\n",
    "df_video_info[\"video_file_name\"] = df_video_info[\"video_file_name\"].apply(lambda x: x.replace(\".MP4\", \"\"))\n",
    "\n",
    "# This is just a hack to get a empty dataframe with the same columns\n",
    "df_annotations = df_video_info.loc[0:-1, :\"date_minut\"]\n",
    "df_annotations[\"annotation_name\"] = \"\"\n",
    "df_annotations[\"frame_name\"] = \"\"\n",
    "df_annotations[\"uncropped\"] = False\n",
    "\n",
    "for col_name in project_labels:\n",
    "    df_annotations[col_name] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames_from_video(video_path:str, frames:list):\n",
    "    \n",
    "    # Check\n",
    "    assert os.path.exists(video_path) and (video_path[-4:].lower() == \".mp4\"), \"Bad video path\"\n",
    "    \n",
    "    # Setup\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_i = -1\n",
    "    return_frames = []\n",
    "    \n",
    "    # Extract and save individual frames as specified by the list `frames`\n",
    "    while cap.isOpened():\n",
    "        frame_i += 1\n",
    "        video_feed_active, frame = cap.read()\n",
    "        \n",
    "        if not video_feed_active:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "            \n",
    "        if frame_i in frames:\n",
    "            return_frames.append(frame)\n",
    "    \n",
    "    return return_frames\n",
    "    \n",
    "def xyxy2xywhn(bb:list, label:int, img_width:int, img_height:int):\n",
    "    # Setup\n",
    "    x1, y1, x2, y2 = bb\n",
    "    bb_width, bb_height = (x2 - x1), (y2 - y1)\n",
    "\n",
    "    # Width and height\n",
    "    bb_width_norm = bb_width / img_width\n",
    "    bb_height_norm = bb_height / img_height\n",
    "\n",
    "    # Center\n",
    "    bb_center_x_norm = (x1 + bb_width / 2) / img_width\n",
    "    bb_center_y_norm = (y1 + bb_height / 2) / img_height\n",
    "\n",
    "    # Yolo format --> `class_name_int center_x center_y width height`\n",
    "    string = str(label)\n",
    "    for s in [bb_center_x_norm, bb_center_y_norm, bb_width_norm, bb_height_norm]:\n",
    "        string += \" \" + str(s)\n",
    "\n",
    "    return string            \n",
    "\n",
    "def extract_bb_info(annotations:list, video_width, video_height):\n",
    "    to_return = {}\n",
    "    bbs_xywhn = []\n",
    "    labels = []\n",
    "    \n",
    "    for annotation in annotations:\n",
    "        # Frame number\n",
    "        frame_number = annotation[\"frame\"]\n",
    "        \n",
    "        # Label\n",
    "        label_int = project_labels_map[annotation[\"label\"]]\n",
    "        labels.append(label_int)\n",
    "        \n",
    "        # Bounding boxes\n",
    "        bb_xywhn = xyxy2xywhn(annotation[\"points\"], label_int, video_width, video_height)\n",
    "        \n",
    "        if frame_number in to_return.keys():\n",
    "            to_return[frame_number] += \"\\n\" + bb_xywhn\n",
    "        else:\n",
    "            to_return[frame_number] = bb_xywhn\n",
    "    \n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset with csv-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_folder_path in tqdm(task_folder_paths):\n",
    "    is_full_size = False\n",
    "    \n",
    "    # Load video path\n",
    "    video_path = list(set(glob(os.path.join(task_folder_path, \"data/*.MP4\")) + glob(os.path.join(task_folder_path, \"data/*.mp4\"))))\n",
    "    assert len(video_path) == 1, \"Expected to find exatcly 1 video\"\n",
    "    video_path = video_path[0]\n",
    "    video_info = U.videos.get_video_info(video_path)\n",
    "    \n",
    "    # Extract video name (need to know the location and date)\n",
    "    with open(os.path.join(task_folder_path, \"task.json\"))as f:\n",
    "        task_name = json.load(f)[\"name\"]\n",
    "        \n",
    "        # Handle the uncropped videos\n",
    "        if task_name[-10:] == '_full_size':\n",
    "            task_name = task_name[:-10]\n",
    "            is_full_size = True\n",
    "        \n",
    "        match = df_video_info[df_video_info[\"mapping_key\"] == task_name]\n",
    "        assert len(match) == 1, \"Expected to find exactly 1 match\"\n",
    "        full_name = match[\"video_file_name\"].values[0]\n",
    "        pass\n",
    "    \n",
    "    # Annotations\n",
    "    annotation_path = os.path.join(task_folder_path, \"annotations.json\")\n",
    "    with open(annotation_path)as f:\n",
    "        annotations = json.load(f)\n",
    "        assert len(annotations) == 1\n",
    "        annotations = annotations[0][\"shapes\"] # Just the format cvat has chosen\n",
    "    \n",
    "    # Frames and corresponding bbs\n",
    "    frame_2_bbs = extract_bb_info(annotations, video_info[\"width\"], video_info[\"height\"])\n",
    "    bb_matching_frames = extract_frames_from_video(video_path, list(frame_2_bbs.keys()))\n",
    "    assert len(frame_2_bbs) == len(bb_matching_frames), \"Shape mismatch between frames and bounding boxes\"\n",
    "    \n",
    "    # Save frames (.png) and annotations (.txt) in yolo-format (class_label x_center, y_center, width, heghti)\n",
    "    for (image, frame_i, bbs) in zip(bb_matching_frames, list(frame_2_bbs.keys()), list(frame_2_bbs.values())):\n",
    "        name_general = full_name + \"_\" + str(frame_i)\n",
    "        save_path_general = os.path.join(save_path, name_general)\n",
    "        \n",
    "        # Write to disk\n",
    "        with open(save_path_general+\".txt\", 'x') as f:\n",
    "            print(bbs, file=f, end=\"\")\n",
    "        cv2.imwrite(save_path_general+\".png\", image)\n",
    "        \n",
    "        # Update annotation dataframe with relevant info\n",
    "        to_append = match.loc[:, :\"date_minut\"]\n",
    "        to_append[\"annotation_name\"] = name_general + \".txt\"\n",
    "        to_append[\"frame_name\"] = name_general + \".png\"\n",
    "        to_append[\"uncropped\"] = is_full_size\n",
    "        \n",
    "        labels = [int(bb.split(\" \")[0]) for bb in bbs.split(\"\\n\")]\n",
    "        for (label_name, label_i) in project_labels_map.items():\n",
    "            to_append[label_name] = labels.count(label_i)\n",
    "        \n",
    "        df_annotations = df_annotations.append(to_append)\n",
    "\n",
    "df_annotations = df_annotations.reset_index(drop=True)\n",
    "df_annotations.to_csv(os.path.join(save_path_csv, \"info.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create .txt file with label_name:label_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\"\n",
    "for k, v in project_labels_map.items():\n",
    "    string += f\"{k}:{v}\\n\"\n",
    "\n",
    "with open(\"../dataset/data_final/labels.txt\", \"x\") as f:\n",
    "    print(string.strip(), file=f, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_bb = []\n",
    "for _ in range(10):\n",
    "    random_name = random.choice(df_annotations[\"frame_name\"].to_list())[:-4]\n",
    "    image_path = glob(f\"{save_path}/{random_name}.png\")[0]\n",
    "    anno_path = glob(f\"{save_path}//{random_name}.txt\")[0]\n",
    "    image_drawn = U.pytorch.yolo_draw_bbs_path(image_path, anno_path)\n",
    "    images_with_bb.append(image_drawn)\n",
    "show(images_with_bb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
