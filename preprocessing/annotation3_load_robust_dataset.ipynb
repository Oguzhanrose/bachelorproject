{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File description\n",
    "Combine images + bounding box annotations from the robust dataset with those of `info.csv` (The ones created in `annotation2_read_cvat_backup.ipynb`). The process was relatively straight forward as the dataset could be exported into the correct format directly from `CVAT`. The only real preprocessing necessary was to remove all images which didn't contain any bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dutils as U\n",
    "U.jupyter_ipython.adjust_screen_width()\n",
    "from dutils.jupyter_ipython import show_image as show\n",
    "import seaborn; seaborn.set_style(\"whitegrid\")\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from natsort import natsorted\n",
    "import shutil\n",
    "import zipfile\n",
    "import shutil\n",
    "from glob import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_folder_path = \"../cvat/robust.zip\"\n",
    "unzip_folder_path = zip_folder_path[:-4]\n",
    "assert os.path.isfile(zip_folder_path) and (zip_folder_path[-4:] == \".zip\"), \"Backup file is invalid\"\n",
    "with zipfile.ZipFile(zip_folder_path) as zip_file:\n",
    "        zip_file.extractall(unzip_folder_path)\n",
    "\n",
    "cvat_dataset_folder_path = os.path.join(unzip_folder_path, \"obj_train_data\")\n",
    "clean_dataset_path = \"../dataset/data_final/data\"\n",
    "csv_path = \"../dataset/data_final/info.csv\"\n",
    "\n",
    "# Have inlcluded both .jpg and .png, but no other formats is legal\n",
    "image_paths = \\\n",
    "    glob(cvat_dataset_folder_path + \"/*.png\") + \\\n",
    "    glob(cvat_dataset_folder_path + \"/*.jpg\") + \\\n",
    "    glob(cvat_dataset_folder_path + \"/*.PNG\") + \\\n",
    "    glob(cvat_dataset_folder_path + \"/*.JPG\")\n",
    "\n",
    "# glob is case insensitive on Windows, but not on Linux so have included upper case extensions which create duplicates on Windows.\n",
    "image_paths = natsorted(list(set(image_paths)))\n",
    "\n",
    "# Load the yolo annotations\n",
    "anno_paths = natsorted(glob(cvat_dataset_folder_path + \"/*.txt\"))\n",
    "\n",
    "# Make sure each image as a corresponding annotation\n",
    "assert len(anno_paths) == len(image_paths)\n",
    "for anno_path, image_path in list(zip(anno_paths, image_paths)):\n",
    "    assert anno_path[:-4] == image_path[:-4], \"Mismatch between the location of image_paths and anno_paths\"\n",
    "\n",
    "df_annotations = pd.read_csv(csv_path)\n",
    "df_annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_labels_map = {\n",
    "     'cycle_helmet': 0,\n",
    "     'cycle_nohelmet': 1,\n",
    "     'cycle_blurred': 2,\n",
    "     'cycle_covered': 3,\n",
    "     'escooter_helmet': 4,\n",
    "     'escooter_nohelmet': 5,\n",
    "     'escooter_blurred': 6,\n",
    "     'escooter_covered': 7,\n",
    "     'headphones': 8,\n",
    "     'earbuds': 9,\n",
    "     'phone': 10,\n",
    "     'hovding': 11,\n",
    "     'cycle_light': 12,\n",
    "     'escooter_light': 13,\n",
    "     'scooter': 14\n",
    "}\n",
    "\n",
    "# The backup file has flipped annotation_labels i.e. 0=14, 1=13 ... \n",
    "# So i will reverse the robust labels aswell (this is admittedly an ugly solution)\n",
    "reverse_label_map = {i:i_reversed for i, i_reversed in enumerate(list(range(14,-1,-1)))}\n",
    "def get_reversed_label(anno_path):\n",
    "    with open(anno_path) as f:\n",
    "        s = f.read()\n",
    "    \n",
    "    return_string = \"\"\n",
    "    \n",
    "    for anno in s.strip().split(\"\\n\"):\n",
    "        splits = anno.strip().split(\" \")\n",
    "        reversed_label = reverse_label_map[int(splits[0])]\n",
    "        new_anno = \" \".join([str(reversed_label)] + splits[1:])\n",
    "        return_string += new_anno + \"\\n\"\n",
    "    return return_string.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy images with at least one bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1\n",
    "for image_path, anno_path in tqdm(list(zip(image_paths, anno_paths))):\n",
    "    with open(anno_path) as f:\n",
    "        anno = f.readlines()\n",
    "    \n",
    "    # If annotation file is empty -> don't save the image\n",
    "    if len(anno) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Setup\n",
    "    i += 1 \n",
    "    name_general = \"robust_\" + str(i)\n",
    "    save_path = os.path.join(clean_dataset_path, name_general)\n",
    "    \n",
    "    # Save to disk\n",
    "    cv2.imwrite(save_path + \".png\", cv2.imread(image_path))\n",
    "    with open(save_path+\".txt\", 'x') as f:\n",
    "        reversed_annotation = get_reversed_label(anno_path)\n",
    "        print(reversed_annotation, file=f, end=\"\")\n",
    "    \n",
    "    # Update annotation dataframe\n",
    "    to_append = df_annotations.iloc[0:1].copy()\n",
    "    to_append.loc[0, \"location\"] = \"internet\"\n",
    "    to_append.loc[0, \"week_day\":\"date_minut\"] = pd.NA\n",
    "    to_append.loc[0, \"annotation_name\"] = name_general + \".txt\"\n",
    "    to_append.loc[0, \"frame_name\"] = name_general + \".png\"\n",
    "    to_append.loc[0, \"cycle_helmet\":] = 0\n",
    "    \n",
    "    with open(save_path+\".txt\") as bbs:\n",
    "        labels = [int(bb.split(\" \")[0]) for bb in bbs.read().strip().split(\"\\n\")]\n",
    "    \n",
    "    for (label_name, label_i) in project_labels_map.items():\n",
    "        to_append[label_name] = labels.count(label_i)\n",
    "    \n",
    "    df_annotations = df_annotations.append(to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations.to_csv(csv_path, index=False)\n",
    "df_annotations[df_annotations[\"location\"] == \"internet\"].loc[:, \"cycle_helmet\":].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing - only robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_bb = []\n",
    "for _ in range(10):\n",
    "    random_name = random.randint(0, max([int(path.split(os.sep)[-1][7:-4]) for path in glob(clean_dataset_path + \"/robust_*\")]))\n",
    "    image_path = f\"{clean_dataset_path}/robust_{random_name}.png\"\n",
    "    anno_path = f\"{clean_dataset_path}/robust_{random_name}.txt\"\n",
    "    image_drawn = U.pytorch.yolo_draw_bbs_path(image_path, anno_path)\n",
    "    images_with_bb.append(image_drawn)\n",
    "\n",
    "show(images_with_bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_bb = []\n",
    "for _ in range(10):\n",
    "    random_name = random.choice(df_annotations[\"frame_name\"].to_list())[:-4]\n",
    "    image_path = glob(f\"{clean_dataset_path}/{random_name}.png\")[0]\n",
    "    anno_path = glob(f\"{clean_dataset_path}//{random_name}.txt\")[0]\n",
    "    image_drawn = U.pytorch.yolo_draw_bbs_path(image_path, anno_path)\n",
    "    images_with_bb.append(image_drawn)\n",
    "\n",
    "show(images_with_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations.loc[:, \"cycle_helmet\":].sum().plot.bar(figsize=(20,8), rot=45)\n",
    "df_annotations.loc[:, \"cycle_helmet\":].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
