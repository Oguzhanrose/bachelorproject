{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File description\n",
    "fourth and last step in the preprocessing. This file takes the cropped videos from `reducer3_crop.ipynb` remove all frames that don't contain humans and/or bikes. This is accomplished using \n",
    "[Ultralytic's implementation](https://github.com/ultralytics/yolov3)\n",
    "of the object detection model YOLOv3 which is provided trough `pytorch`'s model zoo.\n",
    "<br><br>\n",
    "NOTE: YOLO's confidence score is set to the relatively low value of 25\\% which hopefully ensures no frames a missed, but also means some false positives are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dutils as U\n",
    "U.jupyter_ipython.adjust_screen_width()\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "import warnings\n",
    "import random\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\JK/.cache\\torch\\hub\\ultralytics_yolov3_master\n",
      "YOLOv3  2022-2-8 torch 1.8.1+cu111 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 261 layers, 61922845 parameters, 0 gradients, 156.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "OLD_FOLDER_PATH = \"C:/Users/JK/Desktop/reduced_crop\" # Path to the original videos\n",
    "NEW_FOLDER_PATH = \"C:/Users/JK/Desktop/reduced_yolo\" # Path where the processed videos are to be saved\n",
    "TEMP_FOLDER_PATH = \"C:/Users/JK/Desktop/temp_folders\" # Path which temporarily contain frames while processing\n",
    "DEVICE = U.pytorch.get_device()\n",
    "BATCH_SIZE = 60\n",
    "MODEL = torch.hub.load('ultralytics/yolov3', 'yolov3').to(DEVICE).eval()\n",
    "MODEL.conf = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Reduce Function\n",
    "Function description:\n",
    "\n",
    "    1.) Split the video at `video_path` into individual frames and store them in a new temporary folder\n",
    "    2.) Divides these frames into batches and send them through YOLO\n",
    "    3.) Keep only the frame that contains at least 1 human and/or 1 bike\n",
    "    4.) Combine the selected frames into a new video which is saved at `save_video_path`\n",
    "    5.) The temporary folder is deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_frames(video_path:str, save_video_path:str, model, batch_size:int, temp_folder_path:str) -> None:\n",
    "    # Checks\n",
    "    assert os.path.exists(video_path), \"Received bad path\"\n",
    "    assert os.path.exists(temp_folder_path) and os.path.isdir(temp_folder_path), \"Received bad folder path\"\n",
    "    \n",
    "    # Split video into frames (it's probably unwise to keep the frames in RAM, so will store them in temporary folder)\n",
    "    temp_path = os.path.join(temp_folder_path, str(random.getrandbits(128)))\n",
    "    os.mkdir(temp_path)\n",
    "    U.videos.video_to_images(video_path, temp_path)\n",
    "\n",
    "    # Create \"batches\" of paths pointing to the images located in the temporary folder created above\n",
    "    paths = sorted(glob(os.path.join(temp_path, \"*.png\")), key=os.path.getmtime)\n",
    "    batch, batches = [], []\n",
    "    for i, p in enumerate(paths):\n",
    "        batch.append(p)\n",
    "        if i and (((i + 1) % batch_size == 0) or ((i + 1) == len(paths))):\n",
    "            batches.append(batch)\n",
    "            batch = []\n",
    "\n",
    "    # Inference. Check if a human or bicycle is present in the image\n",
    "    # NOTE: 0 and 1 encode person and cycle respectively in COCO\n",
    "    findings = []\n",
    "    for batch in batches:\n",
    "        results = model(batch)\n",
    "        \n",
    "        for p in results.pred:\n",
    "            if any(p[:, 5] < 2): # Keep all frames with at least one human and/or bicycle\n",
    "                findings.append(True)\n",
    "            else:\n",
    "                findings.append(False)\n",
    "\n",
    "    # Remove all frames without a human or a bicycle\n",
    "    assert len(findings) == len(paths), \"Cannot see how this should be legitimate\"\n",
    "    final_image_paths = [path for i, path in enumerate(paths) if findings[i]]\n",
    "    \n",
    "    # If the YOLO found 0 or 1 human --> Add empty/single frame and suffixes the saved file with \"_EMPTY\"\n",
    "    if len(final_image_paths) < 2:\n",
    "        if len(final_image_paths) == 1: print(save_video_path, \" only contains 1 frame\")\n",
    "        grey_image_path = os.path.join(temp_folder_path, \"dummy_image.png\")\n",
    "        info = U.videos.get_video_info(video_path)\n",
    "        cv2.imwrite(grey_image_path, np.ones((info[\"height\"], info[\"width\"], 3)) * 150)\n",
    "        final_image_paths += [grey_image_path for _ in range(5)] # Add 1 seconds of empty video\n",
    "        save_video_path = new_video_path[:-4]+\"_EMPTY\"+\".MP4\"\n",
    "    \n",
    "    # Make the final video from the all frames containing humans/bicycles    \n",
    "    U.videos.images_to_video(final_image_paths, save_video_path, fps=5)\n",
    "\n",
    "    # Remove all temporary files\n",
    "    [os.remove(path) for path in sorted(glob(os.path.join(temp_path, \"*.png\")), key=os.path.getmtime)] \n",
    "    try: \n",
    "        os.rmdir(temp_path)\n",
    "    except PermissionError: \n",
    "        warnings.warn(f\"PermissionError: Was unable to delete the temporary folder at: `{temp_path}`. Remove it manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/JK/Desktop/corrected/temp_18_human\\Valby_18-12-2021\n"
     ]
    }
   ],
   "source": [
    "old_folder_paths = [os.path.abspath(p) for p in glob(os.path.join(OLD_FOLDER_PATH, \"*\"))]\n",
    "new_folder_paths = [os.path.join(NEW_FOLDER_PATH, os.path.basename(p)) for p in old_folder_paths]\n",
    "for new_folder_path in new_folder_paths:\n",
    "    if os.path.exists(new_folder_path): continue\n",
    "    print(new_folder_path)\n",
    "    assert not os.path.exists(new_folder_path), \"Folder already exists\"\n",
    "    assert not os.path.isdir(new_folder_path), \"Received non-folder path\"\n",
    "    os.mkdir(new_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (old_folder_path, new_folder_path) in tqdm(list(zip(old_folder_paths, new_folder_paths))):\n",
    "    for old_video_path in tqdm(glob(os.path.join(old_folder_path, \"*\"))):\n",
    "        new_video_path = os.path.join(new_folder_path, os.path.basename(old_video_path))\n",
    "        \n",
    "        if os.path.exists(new_video_path) or os.path.exists(new_video_path[:-4]+\"_EMPTY.MP4\"): continue\n",
    "        \n",
    "        # Remove all frames without a human or a bicycle\n",
    "        keep_frames(\n",
    "            video_path = old_video_path,\n",
    "            save_video_path = new_video_path,\n",
    "            model = MODEL,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            temp_folder_path = TEMP_FOLDER_PATH\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
