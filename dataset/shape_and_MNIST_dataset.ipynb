{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File description\n",
    "Create the 2 object detection toy datasets: `Shape` and `Object Detection MNIST`. `Shape` is custom made with the help of `opencv`, whereas `Object Detection MNIST` was created with [this github repo](https://github.com/hukkelas/MNIST-ObjectDetection)<br>\n",
    "<br>\n",
    "Both datasets are illustrated below (shape left and MNIST right)\n",
    "<table><tr>\n",
    "<td> <img src=\"../illustration_images/shape_dataset_example.png\" width=\"400\" /> \n",
    "<td> <img src=\"../illustration_images/MNIST_examples.png\" width=\"400\" />\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:75% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dutils as U\n",
    "U.jupyter_ipython.adjust_screen_width(75)\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape\n",
    "The data was created with the following noteworthy settings:\n",
    "\n",
    "    1.) 900 train images, 100 test images.\n",
    "    2.) Shapes: Triangles and circles\n",
    "    3.) Image resolution is 256x256\n",
    "    4.) Bounding box annotation are in YOLO-format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_image_shape(width=256, height=256):\n",
    "    \n",
    "    image = np.zeros((width, height, 3)).astype(np.uint8)\n",
    "    avg_dim = (width+height)/2\n",
    "    annotations = \"\"\n",
    "    \n",
    "    # Pick center and size\n",
    "    c = [random.randint(40, 216), random.randint(40, 216)]\n",
    "    r = random.randint(20,40)\n",
    "    \n",
    "    if random.random() > 0.5:\n",
    "        # Draw rectancle\n",
    "        t_x = [c[0]-r, c[0],  c[0]+r]\n",
    "        t_y = [c[1], c[1]-r*2,  c[1]]\n",
    "        cv2.fillPoly(image, np.array([list(zip(t_x, t_y))]), (180, 119, 31))\n",
    "        \n",
    "        # Annotations\n",
    "        w, h = max(t_x)-min(t_x), max(t_y)-min(t_y)\n",
    "        x, y = c[0], c[1] - h/2\n",
    "        annotations = f\"0 {min(1.0, x/width)} {min(1.0, y/height)} {w/width} {h/height}\"\n",
    "    \n",
    "    else:\n",
    "        # Draw circle and annotations\n",
    "        cv2.circle(image, c, r, color=(14, 127, 255), thickness=-1)\n",
    "        annotations += f\"1 {c[0]/width} {c[1]/height} {r*2/width} {r*2/height}\"\n",
    "    \n",
    "    return image, annotations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "bbs_all = []\n",
    "gen_num = 1000\n",
    "for i in range(gen_num):\n",
    "    image, bbs = get_image_shape()\n",
    "    images.append(image)\n",
    "    bbs_clean = [float(bb) for bb in bbs.split(\" \")]\n",
    "    bbs_all.append(bbs_clean)\n",
    "    \n",
    "# To disk\n",
    "for i, (image, bbs) in enumerate(zip(images, bbs_all)):\n",
    "    dataset_type = \"train\" if i < int(0.9*gen_num) else \"valid\"\n",
    "    U.input_output.make_file(f\"./data_shape/{dataset_type}/labels/{i}.txt\", allow_override=True)\n",
    "    bb_text = \" \".join(str(bb) for bb in bbs)\n",
    "    U.input_output.write_to_file(f\"./data_shape/{dataset_type}/labels/{i}.txt\", bb_text)\n",
    "    cv2.imwrite(f\"./data_shape/{dataset_type}/images/{i}.PNG\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "images_with_bb = []\n",
    "for image, bb in zip(images, bbs_all):\n",
    "    image_with_bb = image.copy()\n",
    "    U.pytorch.yolo_draw_single_bb_cv2(image_with_bb, *bb[1:],  color=[200, 0, 0])\n",
    "    images_with_bb.append(image_with_bb)\n",
    "\n",
    "# Save a picture for the report\n",
    "final_image = U.jupyter_ipython.show_image(random.choices(images_with_bb, k=8), image_border=200, return_image=True)\n",
    "cv2.imwrite(\"./shape_dataset_example.png\", final_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# MNIST\n",
    "The data was created with the following noteworthy settings:\n",
    "\n",
    "    1.) 1000 train images, 1000 test images.\n",
    "    2.) between 1 and 3 digits per images.\n",
    "    3.) Each digit varies from 50 to 100 pixels.\n",
    "    4.) Image resolution is 256x256\n",
    "    5.) Bounding box annotation are in YOLO-format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def xyxy2xywh(bb, img_width=256, img_height=256):\n",
    "    x1, y1, x2, y2 = bb\n",
    "    bb_width, bb_height = (x2 - x1), (y2 - y1)\n",
    "    w, h = bb_width/img_width, bb_height/img_width\n",
    "    x = (x1 + bb_width / 2) / img_width\n",
    "    y = (y1 + bb_height / 2) / img_height\n",
    "    return [x,y,w,h]\n",
    "\n",
    "image_paths = glob(\"C:/Users/JK/Desktop/Onedrive/Bachelor/code_jupyter/mnist_detection/train/images/*.png\")[:8]\n",
    "label_paths = glob(\"C:/Users/JK/Desktop/Onedrive/Bachelor/code_jupyter/mnist_detection/train/labels//*.txt\")[:8]\n",
    "\n",
    "images = []\n",
    "for image_path, label_path in zip(image_paths, label_paths):\n",
    "    image = U.images.load_image(image_path, \"rgb\")\n",
    "    labels_text = U.input_output.read_file(label_path).split(\"\\n\")[1:-1]\n",
    "    labels_xyxy = [list(map(int, l.split(\",\")[1:])) for l in labels_text]\n",
    "    labels_xywh = [xyxy2xywh(l) for l in labels_xyxy]\n",
    "    \n",
    "    for bb in labels_xywh:\n",
    "        U.pytorch.yolo_draw_single_bb_cv2(image, *bb, color=(200,0,0))\n",
    "    images.append(image)\n",
    "\n",
    "# Save a picture for the report\n",
    "final_image = U.jupyter_ipython.show_image(images, image_border=200, return_image=True)\n",
    "cv2.imwrite(\"./MNIST_examples.png\", final_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
